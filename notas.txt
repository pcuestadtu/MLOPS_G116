Repo experimental pel projecte de veritat, contenint arxius necessaris i format adient
Modulo 6 --> pyproject.toml (tambien mirar requirements modulo 2) + invoke (usando tasks.py)
Modulo 2 --> requirements.txt (a partir pipreqs!!, pip list, pip freeze!!!)
Modulo 4 --> launch.json + archivos .py + folder data   --> Comentar en README.md que farem main.py (falta ferlo, ferlo executable script + hydra, etc) + train y evaluate per separat (dues opcions, nomes cal executar una)
Modulo 2 --> environment.yaml (a partir conda list)
Modulo 7 --> codi ben documentat (comments, docstrings) + ruff (para ser pep8 compliant, explica como configurar ruff en pyproject
y diferentes reglas etc para styling) + mypy (typing: comprobar que tingui sentit)
Modulo 8 --> dvc (mirar tema contraseñas, permisos, arxiu config, valorar si crear service account, etc) + googlecloud (guardar data alli) + gdown (descarregar data de altres drives)
Modulo 9 --> Hacer que se pueda ejecutar "train" así tal cual en terminal e.g. (usando [project.scripts]
train = "my_project.train:main" en pyproject). Tambien se puede seguir usando python archivo.py o con el debugger
+ app.command (ver ejemplo creado con iris_classifier.py. Diferencia con typer normal: permite entrar varios comandos) + invoke (crear nuevas taks --> evitar mencionar docker python y acortar codigos)
Modulo 10 --> Docker (docker built: crear imagen + docker run: crear contenedor a partir imagen y train.dockerfile + docker cd/docker run -v: copiar archivos entre
contenedor y máquina) en /dockerfiles + /.devcontainers (abrir VSC en modo dev-container despues de crear archivo.
Nombre archivo ha de ser 100% devcontainer.json --> quizas hay que actualizarlo con devcontainer_cookie.json) -->
Dev Container: Rebuild and Reopen in Container (to enter in this mode). Important:

Docker Tip: If installing the gcloud CLI inside a Docker image, use a single RUN step instead:
RUN echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list && curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg && apt-get update -y && apt-get install google-cloud-cli -y   

· Modulo 11 --> Hydra (crear en configs/config.yaml para almacenar hyperparametros de train.py etc --> Falta hacerlo) --> Hydra es como el substituto de typer
para evitar tener que entrar argumentos en terminal (y solo cambiar archivo yaml; y guarda configuraciones automaticamente en carpeta
creado automaticamente "outputs"!!!!! --> valorar si poner en .gitignore, en teoria si) + logging (simplemente canviem print per log.info i s'emmagatzema
a outputs tmb) + instantiate. Que faria jo: aniria emmagatzemant resultats (imatges i model) a outputs per cada run i, amb el definitiu, llavors els posaria
a models i reports. Tambe mirar final exercise per distribucio!!  Valorar com fijar seed (no nomes amb torch.manual.seed sino amb mes coses!!!)
--> Despres comprobar amb arxiu reproducibility_tester
· Modulo 12 --> Debugging per trobar errors (maxim pot ser ajuda per launch.json)
· Modulo 13 --> Profiling (per enseñar stats temps: snakeviz). PYTORCH (trace.json anarlo guardant
a carpeta outputs que es crea al hydra. Un cop tinguem model final, ho copiem a carpetes definitives
que si que es pugen a git). Per obrir trace.json fer chrome://tracing i load arxiu. Per treball, podem crear
tant arxiu .prof per despres snakeviz (aixo nomes manualment amb terminal
en el model definitiu); y sobretot trace.json per pytorch (aixo implementat dins
de hydra y del train.py). Tensorboard (complement a Pytorch important)-->  http://localhost:6006/#pytorch_profiler
· Modulo 14 (logging) --> Importante integracion Hydra + loguru (ver "my_logger_hydra"), no logging. Archivo .env para guardar
info confidencial/APIS keys,... (wandb) + wandb. IMPORTANTE: En train.py de este repo ya hago wandb (aunque falta hydra y mas cosas 
de otros modulos) --> crea carpeta wandb automaticamente. Acoplar hydra + loguru (carpeta outputs/) amb wandb(carpeta
wandb/). Artifacts!! --> Mirar web wandb (reproducibilitat, punt 5), opcio crear reports (punt 6). Usar arguments project, entity
job_type per wand.init (punt 7)!!

· Modulo 20 --> Comandos 100% necessaris per fer instalacio + autentificacio (en WSL, posant que usuari te acces al bucket)
sudo apt-get update
sudo apt-get install -y ca-certificates
sudo update-ca-certificates
conda install -c conda-forge ca-certificates certifi openssl
sudo apt-get install apt-transport-https ca-certificates gnupg curl
curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg
echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
sudo apt-get update && sudo apt-get install google-cloud-cli
gcloud -h (informatiu, que canceli invoke)
gcloud auth login --no-launch-browser
gcloud auth application-default login --no-launch-browser
gcloud config set project mlops116
pip install --upgrade google-api-python-client
gcloud services enable apigateway.googleapis.com
gcloud services enable servicemanagement.googleapis.com
gcloud services enable servicecontrol.googleapis.com


docker build -f dockerfiles/main.dockerfile \
  --build-arg GOOGLE_CLOUD_PROJECT=dtumlops \
  -t mlops-main:latest .



docker run --rm \
  -e GOOGLE_APPLICATION_CREDENTIALS=/tmp/sa.json \
  -v /home/slupo/MLops/MLOps_G116/dvc-484113-4b1eb26d3ec8.json:/tmp/sa.json:ro \
  -v /tmp/dvc-cache:/tmp/dvc-cache \
  -e WANDB_API_KEY=TU_KEY \
  mlops-main:latest \
  training=exp2 hyperparameters.epochs=1

docker run --rm \
  -e GOOGLE_APPLICATION_CREDENTIALS=/tmp/adc.json \
  -v ~/.config/gcloud/application_default_credentials.json:/tmp/adc.json:ro \
  -v /tmp/dvc-cache:/tmp/dvc-cache \
  -e WANDB_API_KEY=TU_KEY \
  mlops-main:latest \
  training=exp2 hyperparameters.epochs=1



- Faltara añadir en README (esquema) lo de .vscode --> launch.json
- Tambien poner en README.md como hay que ejecutar cada cosa (explicar invoke para train, opcion debugger, hay que estar en carpeta root del repo muy importante
(ya sea para runear desde terminal, desde debugger o lo que sea)!!!!)
- Para invoke, recordar añadir tasks en proyecto para hacer mas facil ejecucion de modulos/ficheros etc (modulo 6 + 9)
- Recordar ir actualizando requirements.txt con pip freeze o pipreqs
- Siempre ejecutar pip install -e . desde el root para adquirir packages (carpeto con _init__.py vacio) y requirements
- La carpeta que contiene _init__.py quiere decir que los archivos son packages y cuyas funciones/classes son modulos. Entonces en nuestro caso hariamos:
from project_test.package (el nombre archivo) import module (nombre funcion, classe dentro de ese archivo)
- if __name__ == "__main__":g
    typer.run(evaluate)
    Lo que hace esto es que ademas de definir funciones/modulos en ese archivo, al hacer python archivo.py tambien se ejecute la funcion, sino habria que crear otro
    archivo que hiciera referencia a este archivo y fuera un output
- Deberiamos añadir más rules en ruff (modulo 7)
- En gitignore, nse si deberiamos procurar que los archivos que se crean al ejecutar data.py y train.py, etc, deberian ser puestos alli
- Falta sobre modulo 11, crear config.yaml
- Crear canvas (inicio)
- Modul 13 --> Crear pytorch(profiler) per train.py i diferent arxius (veure s4/simple_profiler i vae_mnist_pytorch_profiler_solution.py)
